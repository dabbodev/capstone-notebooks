{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Layer\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.initializers import Constant\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\n\nimport cv2\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport math\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T02:45:53.477706Z","iopub.execute_input":"2021-12-29T02:45:53.478036Z","iopub.status.idle":"2021-12-29T02:45:58.495375Z","shell.execute_reply.started":"2021-12-29T02:45:53.47793Z","shell.execute_reply":"2021-12-29T02:45:58.494622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/petfinder-pawpularity-score/'\nscores = pd.read_csv(path + 'train.csv')\nimg_size=300\ncurrent_batch = 0\nlast_batch = 0\nbatchrates = []","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:45:58.497127Z","iopub.execute_input":"2021-12-29T02:45:58.497375Z","iopub.status.idle":"2021-12-29T02:45:58.532313Z","shell.execute_reply.started":"2021-12-29T02:45:58.497343Z","shell.execute_reply":"2021-12-29T02:45:58.531677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encodescore(X):\n    out = [0, 0, 0]\n    if (X < 25):\n        return out\n    elif (X < 50):\n        out = [0, 0, 1]\n        return out\n    elif (X < 75):\n        out = [0, 1, 1]\n        return out\n    else:\n        out = [1, 1, 1]\n        return out\n\ndef preprocessdata(X):\n    X_p = keras.applications.resnet50.preprocess_input(X)\n    return X_p\n        \n\ndef assemble_batch(batch_num, batch_length):\n    start_index = batch_num * batch_length\n    total_length = scores.shape[0]\n    data = []\n    if (batch_num == batches - 1):\n        if (total_length % batches > 0):\n            batch_length = batch_length + (total_length % batches)\n    end_index = start_index + batch_length\n    for x in range(start_index, end_index):\n        entry = scores.iloc[x]\n        try:\n            img_arr = cv2.imread(os.path.join(path + 'train', entry.Id + '.jpg'))[...,::-1] \n            resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n            data.append([resized_arr, entry])\n        except Exception as e:\n            print(e)\n    print(f'Batch {batch_num+1} assembled. Length: {batch_length}')\n    return np.array(data, dtype=object)\n    \ndef train_batch(z, model, batch_length, max_epochs, lastLoss=999, rMetric=\"loss\", f=1, q=1.0, d=0.0, phase=1, ls=4): \n    global batchrates\n    global current_batch\n    global val_x\n    global val_y\n    train = assemble_batch(z, batch_length)\n    current_batch = z\n    x_train = []\n    y_train = []\n    \n    if (phase == 1):     \n        for feature, labels in train:\n            x_train.append(feature)\n            y_train.append(labels[f:])\n\n        del train    \n        \n        for x in range(len(y_train)):\n            y_train[x] = y_train[x].to_list()\n            for y in range(len(y_train[x])):\n                if (y == len(y_train[x]) - 1):\n                    encoded = encodescore(y_train[x][y])\n                    y_train[x][y] = encoded[0]\n                    y_train[x].append(encoded[1])\n                    y_train[x].append(encoded[2])\n                y_train[x][y] = float(y_train[x][y])\n            y_train[x] = np.array(y_train[x])\n        \n        x_train = np.array(x_train) / 255\n        x_train = preprocessdata(x_train)\n    \n        y_train = np.asarray(y_train).astype('float32')\n        \n    elif (phase == 2):\n        for feature, labels in train:\n            x_train.append(feature)\n            y_train.append(labels[-1:])\n            \n        del train \n            \n        for x in range(len(y_train)):\n            y_train[x] = y_train[x].to_list()\n            for y in range(len(y_train[x])):\n                y_train[x][y] = float(y_train[x][y])\n            y_train[x] = np.array(y_train[x])\n            \n        x_train = np.array(x_train) / 255\n        x_train = preprocessdata(x_train)\n        y_train = np.asarray(y_train).astype('float32')\n    \n    history = model.fit(x_train,y_train,epochs = max_epochs,batch_size=ls,shuffle=True,validation_data=(val_x, val_y))   \n    del x_train\n    del y_train\n    del history\n    return model, lastLoss\n\n  \nclass SoftBinaryCap(Layer):\n    def __init__(self):\n        super(SoftBinaryCap, self).__init__()\n\n    def build(self, input_shape):\n        \n        self.w = tf.Variable(initial_value=tf.convert_to_tensor([[1.],[0.]]),\n            trainable=False\n        )\n\n    def call(self, inputs):\n        x = tf.matmul(inputs, self.w)\n        return x\n    \nclass ScoreRenderer(Layer):\n    def __init__(self):\n        super(ScoreRenderer, self).__init__()\n\n    def build(self, input_shape):\n        self.a = self.add_weight(shape=(3,),\n                                 constraint=tf.keras.constraints.NonNeg(),\n                               trainable=True)\n        \n        self.b = self.add_weight(shape=(6,),\n                                 constraint=tf.keras.constraints.NonNeg(),\n                               trainable=True)\n        \n        self.c = self.add_weight(shape=(6,),\n                                 constraint=tf.keras.constraints.NonNeg(),\n                               trainable=True)\n        \n        \n\n    def call(self, inputs): \n        l = tf.shape(inputs)[0]  \n        pos = keras.backend.map_fn(lambda i: i * self.b, inputs[:,:6])\n        neg = keras.backend.map_fn(lambda i: i * self.c, inputs[:,6:12])\n        x = keras.backend.map_fn(lambda i:  i * self.a, inputs[:,12:])\n        x = tf.reduce_sum(x, axis=1)\n        x = keras.backend.reshape(x, (l, 1))\n        pos = tf.reduce_sum(pos, axis=1)\n        neg = tf.reduce_sum(neg, axis=1)\n        pos = keras.backend.reshape(pos, (l, 1))\n        neg = keras.backend.reshape(neg, (l, 1))\n        x = tf.concat([x, (pos - neg)], 1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:45:58.533787Z","iopub.execute_input":"2021-12-29T02:45:58.53419Z","iopub.status.idle":"2021-12-29T02:45:58.572821Z","shell.execute_reply.started":"2021-12-29T02:45:58.534154Z","shell.execute_reply":"2021-12-29T02:45:58.572107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batches = 21\nbatch_length = math.floor(scores.shape[0] / batches)\n\nprint(f'Total Length: {scores.shape[0]} | Batches: {batches} | Batch Length: {batch_length}')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:45:58.575772Z","iopub.execute_input":"2021-12-29T02:45:58.57625Z","iopub.status.idle":"2021-12-29T02:45:58.584628Z","shell.execute_reply.started":"2021-12-29T02:45:58.576215Z","shell.execute_reply":"2021-12-29T02:45:58.583745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_x = []\nval_y = []\nval_data = assemble_batch(batches-1, batch_length)\n\nfor feature, labels in val_data:\n    val_x.append(feature)\n    val_y.append(labels[1:])\n\ndel val_data    \n        \nfor x in range(len(val_y)):\n    val_y[x] = val_y[x].to_list()\n    for y in range(len(val_y[x])):\n        if (y == len(val_y[x]) - 1):\n            encoded = encodescore(val_y[x][y])\n            val_y[x][y] = encoded[0]\n            val_y[x].append(encoded[1])\n            val_y[x].append(encoded[2])\n        val_y[x][y] = float(val_y[x][y])\n    val_y[x] = np.array(val_y[x])\n        \nval_x = np.array(val_x) / 255\nval_x = preprocessdata(val_x)\n    \nval_y = np.asarray(val_y).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:45:58.587221Z","iopub.execute_input":"2021-12-29T02:45:58.587925Z","iopub.status.idle":"2021-12-29T02:46:11.043711Z","shell.execute_reply.started":"2021-12-29T02:45:58.587899Z","shell.execute_reply":"2021-12-29T02:46:11.042953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_model = keras.applications.ResNet50(include_top=False, weights=\"../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", input_tensor=keras.Input(shape=(img_size, img_size, 3)))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:11.045045Z","iopub.execute_input":"2021-12-29T02:46:11.045322Z","iopub.status.idle":"2021-12-29T02:46:16.868509Z","shell.execute_reply.started":"2021-12-29T02:46:11.045287Z","shell.execute_reply":"2021-12-29T02:46:16.867761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in res_model.layers[:143]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:16.869916Z","iopub.execute_input":"2021-12-29T02:46:16.870179Z","iopub.status.idle":"2021-12-29T02:46:16.87832Z","shell.execute_reply.started":"2021-12-29T02:46:16.870146Z","shell.execute_reply":"2021-12-29T02:46:16.877444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class binaryFeatureDetector(keras.Model):\n\n  def __init__(self):\n    super(binaryFeatureDetector, self).__init__()\n    self.dense1 = layers.Dense(128, use_bias=False, kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n    self.dense2 = layers.Dense(64, use_bias=False, kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n    self.dense3 = layers.Dense(32, use_bias=False, kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n    self.dense4 = layers.Dense(16, use_bias=False, kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n    self.dense5 = layers.Dense(8, use_bias=False, kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n    self.softmax = layers.Dense(2, use_bias=False, activation='softmax', kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n    self.cap = SoftBinaryCap()\n\n  def call(self, inputs):\n    x = self.dense1(inputs)\n    x = self.dense2(x)\n    x = self.dense3(x)\n    x = self.dense4(x)\n    x = self.dense5(x)\n    x = self.softmax(x)\n    return self.cap(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:16.879619Z","iopub.execute_input":"2021-12-29T02:46:16.880073Z","iopub.status.idle":"2021-12-29T02:46:16.892356Z","shell.execute_reply.started":"2021-12-29T02:46:16.880039Z","shell.execute_reply":"2021-12-29T02:46:16.891645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ip_shape = (204800,)\ninp = keras.Input(shape=ip_shape)\nconvs = []\nfor x in range(15):\n    \n    convs.append(binaryFeatureDetector()(inp))\n\nout = layers.Concatenate()(convs)\nconv_model = keras.Model(inputs=inp, outputs=out)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:16.914066Z","iopub.execute_input":"2021-12-29T02:46:16.91444Z","iopub.status.idle":"2021-12-29T02:46:17.33165Z","shell.execute_reply.started":"2021-12-29T02:46:16.914353Z","shell.execute_reply":"2021-12-29T02:46:17.33099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = keras.Sequential([\n    res_model,\n    layers.Flatten(),\n    conv_model\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:17.333222Z","iopub.execute_input":"2021-12-29T02:46:17.333457Z","iopub.status.idle":"2021-12-29T02:46:17.898167Z","shell.execute_reply.started":"2021-12-29T02:46:17.333426Z","shell.execute_reply":"2021-12-29T02:46:17.897425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE), optimizer=tf.keras.optimizers.Adadelta(learning_rate=1e-7, rho=(58/59)), metrics=['RootMeanSquaredError', 'binary_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:17.902583Z","iopub.execute_input":"2021-12-29T02:46:17.904596Z","iopub.status.idle":"2021-12-29T02:46:17.932563Z","shell.execute_reply.started":"2021-12-29T02:46:17.904557Z","shell.execute_reply":"2021-12-29T02:46:17.931973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastLoss = 999\noverlap=1\nfor x in range(batches + overlap - 1):\n    if (x >= batches):\n        x = batches - 1\n    for z in range(0, x):\n        print(f'Starting Batch {z+1} out of {batches - 1}')\n        model1, lastLoss = train_batch(z, model1, batch_length, 4, lastLoss, q=100., ls=4)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:46:17.936131Z","iopub.execute_input":"2021-12-29T02:46:17.938Z","iopub.status.idle":"2021-12-29T07:52:35.191418Z","shell.execute_reply.started":"2021-12-29T02:46:17.937952Z","shell.execute_reply":"2021-12-29T07:52:35.190689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model1.layers[2].layers[1:13]:\n    layer.trainable = False\n\nfor layer in model1.layers[0].layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:52:35.197349Z","iopub.execute_input":"2021-12-29T07:52:35.197563Z","iopub.status.idle":"2021-12-29T07:52:35.212234Z","shell.execute_reply.started":"2021-12-29T07:52:35.19752Z","shell.execute_reply":"2021-12-29T07:52:35.209797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_x = []\nval_y = []\n\nval_data = assemble_batch(batches-1, batch_length)\n\nfor feature, labels in val_data:\n    val_x.append(feature)\n    val_y.append(labels[-1:])\n\ndel val_data    \n        \nfor x in range(len(val_y)):\n    val_y[x] = val_y[x].to_list()\n    for y in range(len(val_y[x])):\n        if (y == len(val_y[x]) - 1):\n            val_y[x][y] = float(val_y[x][y])\n        val_y[x][y] = float(val_y[x][y])\n    val_y[x] = np.array(val_y[x])\n        \nval_x = np.array(val_x) / 255\nval_x = preprocessdata(val_x)\n    \nval_y = np.asarray(val_y).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:52:35.213679Z","iopub.execute_input":"2021-12-29T07:52:35.214137Z","iopub.status.idle":"2021-12-29T07:52:47.542748Z","shell.execute_reply.started":"2021-12-29T07:52:35.214092Z","shell.execute_reply":"2021-12-29T07:52:47.542012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wrapper = keras.Sequential([\n    model1,\n    ScoreRenderer(),\n    layers.Dense(1, use_bias=False, input_shape=(None,2), kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:52:47.544261Z","iopub.execute_input":"2021-12-29T07:52:47.544497Z","iopub.status.idle":"2021-12-29T07:52:48.249913Z","shell.execute_reply.started":"2021-12-29T07:52:47.544464Z","shell.execute_reply":"2021-12-29T07:52:48.249227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wrapper.compile(loss=tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE), optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.1, rho=(58/59)), metrics = ['RootMeanSquaredError'])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:52:48.256624Z","iopub.execute_input":"2021-12-29T07:52:48.256883Z","iopub.status.idle":"2021-12-29T07:52:48.274007Z","shell.execute_reply.started":"2021-12-29T07:52:48.256849Z","shell.execute_reply":"2021-12-29T07:52:48.273288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastLoss = 999\noverlap=1\nfor x in range(batches + overlap - 1):\n    if (x >= batches):\n        x = batches - 1\n    for z in range(0, x):\n        print(f'Starting Batch {z+1} out of {batches - 1}')\n        wrapper, lastLoss = train_batch(z, wrapper, batch_length, 4, lastLoss, f=-1, phase=2, ls=4)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:52:48.275586Z","iopub.execute_input":"2021-12-29T07:52:48.27586Z","iopub.status.idle":"2021-12-29T07:53:01.749008Z","shell.execute_reply.started":"2021-12-29T07:52:48.275826Z","shell.execute_reply":"2021-12-29T07:53:01.747762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = []\ntest_results = []\ntest_ids = []\n\nfor filename in os.listdir(path + 'test'):\n    try:\n        test_ids.append(filename[:-4])\n        img_arr = cv2.imread(os.path.join(path + 'test', filename))[...,::-1] \n        resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n        test_data.append(resized_arr)\n        test_data = np.array(test_data) / 255\n        #test_data.reshape(-1, img_size, img_size, 1)\n        test_data = preprocessdata(test_data)\n        test_results.append(wrapper.predict(test_data).tolist()[0])\n        test_data = []\n        \n    except Exception as e:\n        print(e)\n        \nprint(test_results)\nprint(test_ids)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:53:01.750163Z","iopub.status.idle":"2021-12-29T07:53:01.750734Z","shell.execute_reply.started":"2021-12-29T07:53:01.750492Z","shell.execute_reply":"2021-12-29T07:53:01.750517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dict = {'Id': test_ids, 'Pawpularity': test_results}\noutput_df = pd.DataFrame(output_dict)\noutput_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:53:01.751896Z","iopub.status.idle":"2021-12-29T07:53:01.752452Z","shell.execute_reply.started":"2021-12-29T07:53:01.75222Z","shell.execute_reply":"2021-12-29T07:53:01.752246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T07:53:01.753486Z","iopub.status.idle":"2021-12-29T07:53:01.754058Z","shell.execute_reply.started":"2021-12-29T07:53:01.753791Z","shell.execute_reply":"2021-12-29T07:53:01.753816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}