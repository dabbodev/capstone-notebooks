{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import adam_v2\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nimport tensorflow as tf\n\nimport cv2\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-09T05:24:16.825771Z","iopub.execute_input":"2021-11-09T05:24:16.826237Z","iopub.status.idle":"2021-11-09T05:24:23.631912Z","shell.execute_reply.started":"2021-11-09T05:24:16.82615Z","shell.execute_reply":"2021-11-09T05:24:23.631267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/petfinder-pawpularity-score/'\nbatches = 15\nmode = \"train\"\nimg_size=300\n\ndef assemble_batch(batch_num, batch_length, mode='train'):\n    start_index = batch_num * batch_length\n    total_length = scores.shape[0]\n    data = []\n    if (batch_num == batches - 1):\n        if (total_length % batches > 0):\n            batch_length = batch_length + (total_length % batches)\n    end_index = start_index + batch_length\n    for x in range(start_index, end_index):\n        entry = scores.iloc[x]\n        try:\n            img_arr = cv2.imread(os.path.join(path + 'train', entry.Id + '.jpg'))[...,::-1] \n            resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n            data.append([resized_arr, entry])\n        except Exception as e:\n            print(e)\n    print(f'Batch {batch_num+1} assembled. Length: {batch_length}')\n    return np.array(data, dtype=object)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-09T05:24:23.633419Z","iopub.execute_input":"2021-11-09T05:24:23.633661Z","iopub.status.idle":"2021-11-09T05:24:23.643118Z","shell.execute_reply.started":"2021-11-09T05:24:23.633631Z","shell.execute_reply":"2021-11-09T05:24:23.642205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(img_size,img_size,3)))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(180,activation=\"relu\"))\nmodel.add(Dense(128,activation=\"softsign\"))\nmodel.add(Dense(64,activation=\"softplus\"))\nmodel.add(Dense(13, activation=\"softmax\"))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T05:24:23.644478Z","iopub.execute_input":"2021-11-09T05:24:23.645238Z","iopub.status.idle":"2021-11-09T05:24:23.979788Z","shell.execute_reply.started":"2021-11-09T05:24:23.645184Z","shell.execute_reply":"2021-11-09T05:24:23.978791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.RMSprop(learning_rate=0.005)\nimport keras.backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n\nmodel.compile(optimizer = opt , loss = 'squared_hinge' , metrics = ['CategoricalHinge', 'RootMeanSquaredError', 'CategoricalCrossentropy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-09T05:24:23.983204Z","iopub.execute_input":"2021-11-09T05:24:23.983457Z","iopub.status.idle":"2021-11-09T05:24:24.357989Z","shell.execute_reply.started":"2021-11-09T05:24:23.983428Z","shell.execute_reply":"2021-11-09T05:24:24.357182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(path + mode + '.csv')\nbatch_length = math.floor(scores.shape[0] / batches)\nprint(f'Total Length: {scores.shape[0]} | Batches: {batches} | Batch Length: {batch_length}')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T05:24:24.359208Z","iopub.execute_input":"2021-11-09T05:24:24.359467Z","iopub.status.idle":"2021-11-09T05:24:24.404059Z","shell.execute_reply.started":"2021-11-09T05:24:24.359439Z","shell.execute_reply":"2021-11-09T05:24:24.403436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastLoss = 999\nfor z in range(batches):\n    print(f'Starting Batch {z+1} out of {batches}')\n    train = assemble_batch(z, batch_length)\n    x_train = []\n    y_train = []\n\n    for feature, labels in train:\n        x_train.append(feature)\n        y_train.append(np.array(labels[1:]))\n\n    del train    \n        \n    for x in range(len(y_train)):\n        for y in range(len(y_train[x])):\n            y_train[x][y] = float(y_train[x][y])\n            if (y == len(y_train[x] - 1)):\n                y_train[x][y] = y_train[x][y] / 100\n        y_train[x] = np.array(y_train[x])\n\n    x_train = np.array(x_train) / 255\n    x_train.reshape(-1, img_size, img_size, 1)\n    y_train = np.asarray(y_train).astype('float32')\n    \n    t_model = model\n    e = 10\n    passing = 0\n    \n    while (passing == 0):\n        history = model.fit(x_train,y_train,epochs = e)\n        l_hist = history.history['root_mean_squared_error']     \n        trend = 0\n        for x in range(len(l_hist)):\n            if (x > 0):\n                if (l_hist[x] < lastLoss):\n                    trend = trend - 1\n                else:\n                    trend = trend + 1\n            lastLoss = l_hist[x]\n                    \n        if (trend >= 0):\n            e = 10\n            passing = 1\n        elif (e > 1):\n            if (l_hist[0] < l_hist[len(l_hist) - 1]):\n                e = 10\n                passing = 1\n            else:\n                e = e - 1\n                model = t_model\n        else:\n            e = 10\n            passing = 1\n        \n    del x_train\n    del y_train","metadata":{"execution":{"iopub.status.busy":"2021-11-09T05:24:24.404949Z","iopub.execute_input":"2021-11-09T05:24:24.405778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(model)\nmodel2.add(Dense(1, activation=\"softmax\"))\nmodel2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.001)\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))\nmodel2.compile(optimizer = opt , loss = root_mean_squared_error , metrics = ['CategoricalHinge', 'RootMeanSquaredError', 'accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastLoss = 999\nfor z in range(batches):\n    print(f'Starting Batch {z+1} out of {batches}')\n    train = assemble_batch(z, batch_length)\n    x_train = []\n    y_train = []\n\n    for feature, labels in train:\n        x_train.append(feature)\n        y_train.append(np.array(labels[-1:]))\n\n    del train    \n        \n    for x in range(len(y_train)):\n        for y in range(len(y_train[x])):\n            y_train[x][y] = float(y_train[x][y])\n            y_train[x][y] = y_train[x][y] / 100\n        y_train[x] = np.array(y_train[x])\n\n    x_train = np.array(x_train) / 255\n    x_train.reshape(-1, img_size, img_size, 1)\n    y_train = np.asarray(y_train).astype('float32')\n    \n    t_model = model2\n    e = 10\n    passing = 0\n    \n    while (passing == 0):\n        history = model2.fit(x_train,y_train,epochs = e)\n        l_hist = history.history['loss']     \n        trend = 0\n        for x in range(len(l_hist)):\n            if (x > 0):\n                if (l_hist[x] > lastLoss):\n                    trend = trend - 1\n                else:\n                    trend = trend + 1\n            lastLoss = l_hist[x]\n                    \n        if (trend >= 0):\n            e = 10\n            passing = 1\n        elif (e > 1):\n            e = e - 1\n            model2 = t_model\n        else:\n            e = 10\n            passing = 1\n        \n    del x_train\n    del y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = []\ntest_results = []\n\nfor filename in os.listdir(path + 'test'):\n    try:\n        img_arr = cv2.imread(os.path.join(path + 'test', filename))[...,::-1] \n        resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n        test_data.append(resized_arr)\n        \n    except Exception as e:\n        print(e)\n        \ntest_data = np.array(test_data) / 255\ntest_data.reshape(-1, img_size, img_size, 1)\ntest_results.append(model2.predict(test_data))\nprint(test_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}